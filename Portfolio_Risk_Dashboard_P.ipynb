{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e6892b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3650d682",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SET UP LOGGER\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
    "    handlers=[\n",
    "        logging.FileHandler(\"stock_data.log\"),\n",
    "        logging.StreamHandler()\n",
    "    ]       \n",
    ")\n",
    "logger = logging.getLogger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5283b2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GET USER TICKERS\n",
    "def get_user_tickers(n=5):\n",
    "    tickers = []\n",
    "    for i in range(n):\n",
    "        ticker = input(f\"Enter in your ticker {i + 1}: \").upper()\n",
    "        tickers.append(ticker)\n",
    "    return tickers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4d4d0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FETCH HISTORICAL DATA FOR EACH TICKER\n",
    "def fetch_data(tickers, start=\"2020-01-01\", end=\"2024-12-31\"):\n",
    "    try:\n",
    "        logger.info(f\"Fetching data for tickers: {', '.join(tickers)}\")\n",
    "        raw_data = yf.download(tickers, start=start, end=end)\n",
    "\n",
    "        if raw_data is None or raw_data.empty:\n",
    "            raise ValueError(\"No data fetched. Please check the ticker symbols.\")\n",
    "\n",
    "        logger.debug(f\"Raw data columns: {raw_data.columns}\")\n",
    "\n",
    "        # Handle multiple tickers\n",
    "        if isinstance(raw_data.columns, pd.MultiIndex):\n",
    "            try:\n",
    "                df = raw_data.xs('Adj Close', level=0, axis=1)\n",
    "                logger.info(\"Using 'Adj Close' for all tickers.\")\n",
    "            except KeyError:\n",
    "                logger.warning(\"'Adj Close' not found — falling back to 'Close'\")\n",
    "                df = raw_data.xs('Close', level=0, axis=1)\n",
    "        else:\n",
    "            # Single ticker fallback\n",
    "            if 'Adj Close' in raw_data.columns:\n",
    "                df = raw_data[['Adj Close']].copy()\n",
    "                df.columns = [tickers[0]]\n",
    "            elif 'Close' in raw_data.columns:\n",
    "                logger.warning(\"'Adj Close' not found — using 'Close' instead.\")\n",
    "                df = raw_data[['Close']].copy()\n",
    "                df.columns = [tickers[0]]\n",
    "            else:\n",
    "                raise KeyError(\"Neither 'Adj Close' nor 'Close' found in single-level data.\")\n",
    "\n",
    "        df.dropna(inplace=True)\n",
    "        logger.info(f\"Successfully fetched price data with shape {df.shape}\")\n",
    "        return df\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error fetching data: {e}\")\n",
    "        return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c22a7b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE DATA TO CSV\n",
    "def save_data(df, path=\"data/raw_prices.csv\"):\n",
    "    os.makedirs(\"data\", exist_ok=True)\n",
    "    try:\n",
    "        df.to_csv(path)\n",
    "        logger.info(f\"Data saved to {path}\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error saving data: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1f6eaaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-16 09:16:49,824 - INFO - Fetching data for tickers: AAPL, NVDA, MSFT, JNJ, TSLA\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YF.download() has changed argument auto_adjust default to True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  5 of 5 completed\n",
      "2025-04-16 09:16:51,654 - WARNING - 'Adj Close' not found — falling back to 'Close'\n",
      "2025-04-16 09:16:51,656 - INFO - Successfully fetched price data with shape (1257, 5)\n",
      "2025-04-16 09:16:51,683 - INFO - Data saved to data/raw_prices.csv\n",
      "2025-04-16 09:16:51,684 - INFO - Script execution completed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample of data downloaded:\n",
      "Ticker            AAPL         JNJ        MSFT        NVDA        TSLA\n",
      "Date                                                                  \n",
      "2024-12-23  254.989655  144.116409  434.379028  139.657150  430.600006\n",
      "2024-12-24  257.916443  144.691803  438.450836  140.207108  462.279999\n",
      "2024-12-26  258.735504  144.423935  437.233276  139.917130  454.130005\n",
      "2024-12-27  255.309296  143.898148  429.668457  136.997391  431.660004\n",
      "2024-12-30  251.923019  142.201721  423.979858  137.477356  417.410004\n"
     ]
    }
   ],
   "source": [
    "# MAIN EXECUTION\n",
    "def main():\n",
    "    # Get user tickers\n",
    "    tickers = get_user_tickers()\n",
    "    df = fetch_data(tickers)\n",
    "\n",
    "    if df.empty:\n",
    "        logger.error(\"No data fetched. Exiting.\")\n",
    "    else:\n",
    "        print(\"\\nSample of data downloaded:\")\n",
    "        print(df.tail())\n",
    "        save_data(df)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "    logger.info(\"Script execution completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e8f2b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CALCULATE DAILY RETURNS FOR EACH ASSET IN PORTFOLIO\n",
    "def calculate_daily_returns(prices_df):\n",
    "    \"\"\"\n",
    "    This section calculates the daily percentage returns from a DataFrame of prices.\n",
    "\n",
    "    Parameters:\n",
    "        prices_df (pd.DataFrame): DataFrame containing price data with dates as index and tickers as columns.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame of daily percentage returns with the same index as prices_df.\n",
    "    \"\"\"\n",
    "\n",
    "    returns = prices_df.pct_change().dropna()\n",
    "    return returns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e140638",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                AAPL       JNJ      MSFT      NVDA      TSLA\n",
      "Date                                                        \n",
      "2024-12-23  0.003065  0.005538 -0.003092  0.036897  0.022657\n",
      "2024-12-24  0.011478  0.003993  0.009374  0.003938  0.073572\n",
      "2024-12-26  0.003176 -0.001851 -0.002777 -0.002068 -0.017630\n",
      "2024-12-27 -0.013242 -0.003641 -0.017302 -0.020868 -0.049479\n",
      "2024-12-30 -0.013263 -0.011789 -0.013240  0.003503 -0.033012\n"
     ]
    }
   ],
   "source": [
    "# TESTING THE FUNCTION\n",
    "df_prices = pd.read_csv(\"data/raw_prices.csv\", index_col=\"Date\", parse_dates=True)\n",
    "# print(df_prices.head())\n",
    "\n",
    "df_returns = calculate_daily_returns(df_prices)\n",
    "print(df_returns.tail())    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bdf08b4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 day VaR at 95% confidence level:\n",
      "AAPL   -0.030369\n",
      "JNJ    -0.016257\n",
      "MSFT   -0.027952\n",
      "NVDA   -0.055386\n",
      "TSLA   -0.073289\n",
      "Name: 0.95, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# CALCULATE THE HISTORICAL VALUE AT RISK (VaR) FOR EACH ASSET IN PORTFOLIO\n",
    "def historical_var(df_returns, alpha=0.05):\n",
    "    \"\"\"\n",
    "    This function calculates the historical Value at Risk (VaR) for a given DataFrame of returns.\n",
    "\n",
    "    Parameters:\n",
    "        returns_df (pd.DataFrame): DataFrame containing daily returns with dates as index and tickers as columns.\n",
    "        alpha (float): Significance level for VaR calculation (default is 0.05 for 95% confidence level).\n",
    "\n",
    "    Returns:\n",
    "        pd.Series: Series containing the VaR for each asset at the specified confidence level.\n",
    "    \"\"\"\n",
    "\n",
    "    var = df_returns.quantile(1 - alpha)\n",
    "    return -var # Return as positive value for VaR (losses are negative)\n",
    "\n",
    "# TESTING THE FUNCTION\n",
    "var_95 = historical_var(df_returns, alpha=0.05)\n",
    "print(\"1 day VaR at 95% confidence level:\")\n",
    "print(var_95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "56ab9e7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parametric VaR at 95% confidence level:\n",
      "AAPL   -0.034024\n",
      "JNJ    -0.020544\n",
      "MSFT   -0.032605\n",
      "NVDA   -0.058907\n",
      "TSLA   -0.072645\n",
      "dtype: float64\n",
      "\n",
      "Interpreting the results:\n",
      "There is a 5.0% chance that the price of AAPL will drop by more than -3.40% in one day.\n",
      "There is a 5.0% chance that the price of JNJ will drop by more than -2.05% in one day.\n",
      "There is a 5.0% chance that the price of MSFT will drop by more than -3.26% in one day.\n",
      "There is a 5.0% chance that the price of NVDA will drop by more than -5.89% in one day.\n",
      "There is a 5.0% chance that the price of TSLA will drop by more than -7.26% in one day.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\roman\\AppData\\Local\\Temp\\ipykernel_53624\\405750789.py:30: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  print(f\"There is a {alpha*100}% chance that the price of {df_returns.columns[i]} will drop by more than {var_param_95[i]:.2%} in one day.\")\n"
     ]
    }
   ],
   "source": [
    "# CALCULATE PARAMETRIC VALUE AT RISK (VaR) FOR EACH ASSET IN PORTFOLIO\n",
    "from scipy.stats import norm\n",
    "def parametric_var(df_returns, alpha=0.05):\n",
    "    \"\"\"\n",
    "    This function calculates the parametric Value at Risk (VaR) for a given DataFrame of returns.\n",
    "\n",
    "    Parameters:\n",
    "        returns_df (pd.DataFrame): DataFrame containing daily returns with dates as index and tickers as columns.\n",
    "        alpha (float): Significance level for VaR calculation (default is 0.05 for 95% confidence level).\n",
    "\n",
    "    Returns:\n",
    "        pd.Series: Series containing the VaR for each asset at the specified confidence level.\n",
    "    \"\"\"\n",
    "\n",
    "    z_score = norm.ppf(1 - alpha)  # Z-score for the given confidence level\n",
    "    mu = df_returns.mean() # Mean of returns\n",
    "    sigma = df_returns.std() # Standard deviation of returns\n",
    "\n",
    "    var_param = -(mu + z_score * sigma)  # VaR formula\n",
    "    return var_param\n",
    "\n",
    "# TESTING THE FUNCTION\n",
    "alpha = 0.05\n",
    "var_param_95 = parametric_var(df_returns, alpha=0.05)\n",
    "print (\"Parametric VaR at 95% confidence level:\")\n",
    "print(var_param_95)\n",
    "\n",
    "print(\"\\nInterpreting the results:\")\n",
    "for i in range(len(var_param_95)):\n",
    "    print(f\"There is a {alpha*100}% chance that the price of {df_returns.columns[i]} will drop by more than {var_param_95[i]:.2%} in one day.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ce26178b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annualized Sharpe Ratios:\n",
      "AAPL    0.913862\n",
      "JNJ     0.170327\n",
      "MSFT    0.789172\n",
      "NVDA    1.417582\n",
      "TSLA    1.119999\n",
      "dtype: float64\n",
      "\n",
      "Interpreting the results:\n",
      "AAPL earns 0.91 units of return per unit of risk annually.\n",
      "JNJ earns 0.17 units of return per unit of risk annually.\n",
      "MSFT earns 0.79 units of return per unit of risk annually.\n",
      "NVDA earns 1.42 units of return per unit of risk annually.\n",
      "TSLA earns 1.12 units of return per unit of risk annually.\n",
      "\n",
      "Further interpreting the Sharpe Ratio:\n",
      "AAPL has a Sharpe Ratio less than 1, indicating it earns less return per unit of risk.\n",
      "JNJ has a Sharpe Ratio less than 1, indicating it earns less return per unit of risk.\n",
      "MSFT has a Sharpe Ratio less than 1, indicating it earns less return per unit of risk.\n",
      "NVDA has a Sharpe Ratio between 1 and 2, indicating it earns a reasonable return per unit of risk.\n",
      "TSLA has a Sharpe Ratio between 1 and 2, indicating it earns a reasonable return per unit of risk.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\roman\\AppData\\Local\\Temp\\ipykernel_53624\\3901875079.py:36: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  print(f\"{df_returns.columns[i]} earns {sharpe_ratios[i]:.2f} units of return per unit of risk annually.\")\n"
     ]
    }
   ],
   "source": [
    "# CALCULATE SHARPE RATIO FOR EACH ASSET IN PORTFOLIO\n",
    "def calculate_sharpe_ratio(df_returns, risk_free_rate=0.01, annualize=True):\n",
    "    \"\"\"\n",
    "    This function calculates the Sharpe Ratio for a given DataFrame of returns.\n",
    "\n",
    "    Parameters:\n",
    "        df_returns (pd.DataFrame): DataFrame containing daily returns with dates as index and tickers as columns.\n",
    "        risk_free_rate (float): Risk-free rate (default is 0.01 for 1%).\n",
    "\n",
    "    Returns:\n",
    "        pd.Series: Series containing the Sharpe Ratio for each asset.\n",
    "    \"\"\"\n",
    "\n",
    "    # Convert annual risk-free rate to daily\n",
    "    rf_daily = (1 + risk_free_rate) ** (1/252) - 1\n",
    "\n",
    "    excess_returns = df_returns.mean() - rf_daily\n",
    "    volatility = df_returns.std()\n",
    "\n",
    "    sharpe_daily = excess_returns / volatility\n",
    "\n",
    "    if annualize:\n",
    "        sharpe_annual = sharpe_daily * np.sqrt(252)  # Annualize the Sharpe Ratio\n",
    "        return sharpe_annual\n",
    "    else:\n",
    "        return sharpe_daily\n",
    "    \n",
    "# TESTING THE FUNCTION\n",
    "sharpe_ratios = calculate_sharpe_ratio(df_returns, risk_free_rate=0.01, annualize=True)\n",
    "print(\"Annualized Sharpe Ratios:\")\n",
    "print(sharpe_ratios)\n",
    "\n",
    "# INTERPRET RESULTS\n",
    "print(\"\\nInterpreting the results:\")\n",
    "for i in range(len(sharpe_ratios)):\n",
    "    print(f\"{df_returns.columns[i]} earns {sharpe_ratios[i]:.2f} units of return per unit of risk annually.\")\n",
    "\n",
    "\n",
    "# FURTHER INTERPRETATION OF SHARPE RATIO\n",
    "print(\"\\nFurther interpreting the Sharpe Ratio:\")\n",
    "for i in range(len(sharpe_ratios)):\n",
    "    if sharpe_ratios.iloc[i] < 0:\n",
    "        print(f\"{df_returns.columns[i]} has a negative Sharpe Ratio, indicating it underperforms the risk-free rate.\")\n",
    "    elif sharpe_ratios.iloc[i] < 1:\n",
    "        print(f\"{df_returns.columns[i]} has a Sharpe Ratio less than 1, indicating it earns less return per unit of risk.\")\n",
    "    elif sharpe_ratios.iloc[i] < 2:\n",
    "        print(f\"{df_returns.columns[i]} has a Sharpe Ratio between 1 and 2, indicating it earns a reasonable return per unit of risk.\")\n",
    "    else:\n",
    "        print(f\"{df_returns.columns[i]} has a Sharpe Ratio greater than 2, indicating it earns a high return per unit of risk.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "374b4330",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Drawdown:\n",
      "AAPL    0.314273\n",
      "JNJ     0.273663\n",
      "MSFT    0.371485\n",
      "NVDA    0.663351\n",
      "TSLA    0.736322\n",
      "dtype: float64\n",
      "\n",
      "Interpreting the results:\n",
      "AAPL experienced a maximum drawdown of 31.43% from its peak price to trough.\n",
      "JNJ experienced a maximum drawdown of 27.37% from its peak price to trough.\n",
      "MSFT experienced a maximum drawdown of 37.15% from its peak price to trough.\n",
      "NVDA experienced a maximum drawdown of 66.34% from its peak price to trough.\n",
      "TSLA experienced a maximum drawdown of 73.63% from its peak price to trough.\n",
      "\n",
      "Further interpreting the Maximum Drawdown:\n",
      "AAPL had a maximum drawdown greater than 30%, indicating high volatility and risk.\n",
      "JNJ had a maximum drawdown between 20% and 30%, indicating significant volatility.\n",
      "MSFT had a maximum drawdown greater than 30%, indicating high volatility and risk.\n",
      "NVDA had a maximum drawdown greater than 30%, indicating high volatility and risk.\n",
      "TSLA had a maximum drawdown greater than 30%, indicating high volatility and risk.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\roman\\AppData\\Local\\Temp\\ipykernel_53624\\3520932235.py:32: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  print(f\"{df_prices.columns[i]} experienced a maximum drawdown of {max_dd[i]:.2%} from its peak price to trough.\")\n",
      "C:\\Users\\roman\\AppData\\Local\\Temp\\ipykernel_53624\\3520932235.py:37: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  if max_dd[i] < 0.1:\n",
      "C:\\Users\\roman\\AppData\\Local\\Temp\\ipykernel_53624\\3520932235.py:39: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  elif max_dd[i] < 0.2:\n",
      "C:\\Users\\roman\\AppData\\Local\\Temp\\ipykernel_53624\\3520932235.py:41: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  elif max_dd[i] < 0.3:\n"
     ]
    }
   ],
   "source": [
    "# CALCULATE MAXIMUM DRAWDOWN FOR EACH ASSET IN PORTFOLIO\n",
    "def calculate_max_drawdown(df_prices):\n",
    "    \"\"\"\n",
    "    This function calculates the maximum drawdown for a given DataFrame of prices.\n",
    "\n",
    "    Parameters:\n",
    "        df_prices (pd.DataFrame): DataFrame containing price data with dates as index and tickers as columns.\n",
    "\n",
    "    Returns:\n",
    "        pd.Series: Series containing the maximum drawdown for each asset.\n",
    "    \"\"\"\n",
    "\n",
    "    drawdowns = {}\n",
    "\n",
    "    for ticker in df_prices.columns:\n",
    "        prices = df_prices[ticker]\n",
    "        rolling_max = prices.cummax()\n",
    "        drawdown = (prices / rolling_max) - 1  # Calculate drawdown\n",
    "        max_drawdown = drawdown.min()\n",
    "        drawdowns[ticker] = abs(max_drawdown)  # Store as positive value\n",
    "    \n",
    "    return pd.Series(drawdowns)\n",
    "\n",
    "# TESTING THE FUNCTION\n",
    "max_dd = calculate_max_drawdown(df_prices)\n",
    "print(\"Maximum Drawdown:\")\n",
    "print(max_dd)\n",
    "\n",
    "# INTERPRET RESULTS\n",
    "print(\"\\nInterpreting the results:\")\n",
    "for i in range(len(max_dd)):\n",
    "    print(f\"{df_prices.columns[i]} experienced a maximum drawdown of {max_dd[i]:.2%} from its peak price to trough.\")\n",
    "\n",
    "# FURTHER INTERPRETATION OF MAXIMUM DRAWDOWN\n",
    "print(\"\\nFurther interpreting the Maximum Drawdown:\")\n",
    "for i in range(len(max_dd)):\n",
    "    if max_dd[i] < 0.1:\n",
    "        print(f\"{df_prices.columns[i]} had a maximum drawdown of less than 10%, indicating relatively stable performance.\")\n",
    "    elif max_dd[i] < 0.2:\n",
    "        print(f\"{df_prices.columns[i]} had a maximum drawdown between 10% and 20%, indicating moderate volatility.\")\n",
    "    elif max_dd[i] < 0.3:\n",
    "        print(f\"{df_prices.columns[i]} had a maximum drawdown between 20% and 30%, indicating significant volatility.\")\n",
    "    else:\n",
    "        print(f\"{df_prices.columns[i]} had a maximum drawdown greater than 30%, indicating high volatility and risk.\")\n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9c1841e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rolling Volatility (20-day window):\n",
      "                AAPL       JNJ      MSFT      NVDA      TSLA\n",
      "Date                                                        \n",
      "2024-12-23  0.141174  0.145646  0.200234  0.367499  0.595966\n",
      "2024-12-24  0.140134  0.145684  0.201738  0.333764  0.604523\n",
      "2024-12-26  0.139406  0.145385  0.188727  0.333502  0.613655\n",
      "2024-12-27  0.152639  0.141766  0.194785  0.339849  0.647214\n",
      "2024-12-30  0.162911  0.144786  0.201190  0.331227  0.661656\n",
      "\n",
      "Interpreting the results:\n",
      "The rolling volatility for AAPL is 16.29% over the last 20 days.\n",
      "The rolling volatility for JNJ is 14.48% over the last 20 days.\n",
      "The rolling volatility for MSFT is 20.12% over the last 20 days.\n",
      "The rolling volatility for NVDA is 33.12% over the last 20 days.\n",
      "The rolling volatility for TSLA is 66.17% over the last 20 days.\n"
     ]
    }
   ],
   "source": [
    "# CALCULATE ROLLING VOLATILITY FOR EACH ASSET IN PORTFOLIO\n",
    "def rolling_volatility(df_returns, window=20):\n",
    "    \"\"\"\n",
    "    This function calculates the rolling volatility for a given DataFrame of returns.\n",
    "\n",
    "    Parameters:\n",
    "        df_returns (pd.DataFrame): DataFrame containing daily returns with dates as index and tickers as columns.\n",
    "        window (int): Rolling window size (default is 20 days).\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame containing the rolling volatility for each asset.\n",
    "    \"\"\"\n",
    "\n",
    "    rolling_vol = df_returns.rolling(window).std() * np.sqrt(252)  # Annualize the volatility\n",
    "    return rolling_vol\n",
    "\n",
    "# TESTING THE FUNCTION\n",
    "rolling_vol = rolling_volatility(df_returns, window=20)\n",
    "print(\"Rolling Volatility (20-day window):\")\n",
    "print(rolling_vol.tail())\n",
    "\n",
    "# INTERPRET RESULTS\n",
    "print(\"\\nInterpreting the results:\")\n",
    "for i in range(len(rolling_vol.columns)):\n",
    "    print(f\"The rolling volatility for {rolling_vol.columns[i]} is {rolling_vol.iloc[-1, i]:.2%} over the last 20 days.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "89a2f268",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MEASURE PORTFOLIO PERFORMANCE\n",
    "def portfolio_performance(df_returns, weights):\n",
    "    \"\"\"\n",
    "    This function calculates the expected return and volatility of a portfolio.\n",
    "\n",
    "    Parameters:\n",
    "        df_returns (pd.DataFrame): DataFrame containing daily returns with dates as index and tickers as columns.\n",
    "        weights (list): List of weights for each asset in the portfolio.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Expected return and volatility of the portfolio.\n",
    "    \"\"\"\n",
    "\n",
    "    # Ensure weights sum to 1\n",
    "    if not np.isclose(np.sum(weights), 1):\n",
    "        raise ValueError(\"Weights must sum to 1.\")\n",
    "\n",
    "    # Calculate expected return and volatility\n",
    "    expected_return = np.dot(weights, df_returns.mean()) * 252  # Annualize the return\n",
    "    expected_volatility = np.sqrt(np.dot(weights, np.dot(df_returns.cov() * 252, weights)))  # Annualize the volatility\n",
    "\n",
    "    return expected_return, expected_volatility\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1eed54f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal weight for AAPL: 5.94%\n",
      "Optimal weight for JNJ: 80.34%\n",
      "Optimal weight for MSFT: 11.54%\n",
      "Optimal weight for NVDA: 0.00%\n",
      "Optimal weight for TSLA: 2.18%\n",
      "\n",
      "Expected return of the minimum variance portfolio: 9.82%\n",
      "Expected volatility of the minimum variance portfolio: 18.79%\n"
     ]
    }
   ],
   "source": [
    "# DEFINE PORTFOLIO WEIGHTS USING MINIMUM VARIANCE OPTIMIZATION\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "def min_variance_portfolio(df_returns):\n",
    "    \"\"\"\n",
    "    This function calculates the minimum variance portfolio weights using historical return covariance.\n",
    "\n",
    "    Parameters:\n",
    "        df_returns (pd.DataFrame): DataFrame containing daily returns with dates as index and tickers as columns.\n",
    "\n",
    "    Returns:\n",
    "        list: List of weights for the minimum variance portfolio.\n",
    "    \"\"\"\n",
    "    n_assets = df_returns.shape[1]\n",
    "    cov_matrix = df_returns.cov() * 252  # Annualize the covariance matrix\n",
    "\n",
    "    # Initial guess for weights\n",
    "    init_guess = np.ones(n_assets) / n_assets\n",
    "\n",
    "    # Constraints: weights sum to 1\n",
    "    constraints = ({'type' : 'eq', 'fun': lambda w: np.sum(w) - 1})\n",
    "\n",
    "    # Bounds for weights: between 0 and 1\n",
    "    bounds = [(0.0, 1.0)] * n_assets\n",
    "\n",
    "    # Optimization function to minimize portfolio variance\n",
    "    def portfolio_volatility(w):\n",
    "        return np.sqrt(np.dot(w, np.dot(cov_matrix * 252, w)))\n",
    "    \n",
    "    result = minimize(portfolio_volatility, init_guess, method='SLSQP', bounds=bounds, constraints=constraints)\n",
    "\n",
    "    if not result.success:\n",
    "        raise ValueError(\"Optimization failed.\", result.message)\n",
    "    \n",
    "    return result.x\n",
    "\n",
    "# TESTING THE FUNCTION\n",
    "optimal_weights = min_variance_portfolio(df_returns)\n",
    "\n",
    "for i in range(len(optimal_weights)):\n",
    "    print(f\"Optimal weight for {df_returns.columns[i]}: {optimal_weights[i]:.2%}\")\n",
    "\n",
    "# CALCULATE EXPECTED RETURN AND VOLATILITY OF THE MINIMUM VARIANCE PORTFOLIO\n",
    "expected_return, expected_volatility = portfolio_performance(df_returns, optimal_weights)\n",
    "print(f\"\\nExpected return of the minimum variance portfolio: {expected_return:.2%}\")\n",
    "print(f\"Expected volatility of the minimum variance portfolio: {expected_volatility:.2%}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e7ec062e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Major Holdings:\n",
      "• JNJ makes up 80.34% of the portfolio — likely due to its lower volatility or better diversification.\n",
      "• MSFT makes up 11.54% of the portfolio — likely due to its lower volatility or better diversification.\n",
      "• AAPL makes up 5.94% of the portfolio — likely due to its higher volatility or lower diversification benefits.\n",
      "• NVDA makes up 0.00% of the portfolio — likely due to its higher volatility or lower diversification benefits.\n",
      "• TSLA makes up 2.18% of the portfolio — likely due to its higher volatility or lower diversification benefits.\n",
      "\n",
      "Expected Portfolio Performance:\n",
      "The expected annual return is 9.82%, with an annualized volatility of 18.79%.\n",
      "This indicates a relatively low-risk portfolio, applicable for a conservative approach.\n"
     ]
    }
   ],
   "source": [
    "# TRANSLATION OF THE RESULTS\n",
    "def explain_min_var_portfolio(weights, tickers, expected_return, expected_volatility, threshold=0.1):\n",
    "    \"\"\"\n",
    "    This function explains the minimum variance portfolio results.\n",
    "\n",
    "    Parameters:\n",
    "        weights (list or np.ndarray): Optimal asset weights\n",
    "        tickers (list): List of asset names\n",
    "        expected_return (float): Portfolio return (annualized)\n",
    "        expected_volatility (float): Portfolio volatility (annualized)\n",
    "        threshold (float): Weight threshold to determine major vs minor holdings\n",
    "    \"\"\"\n",
    "    explanation = []\n",
    "\n",
    "    # Identify major and minor holdings\n",
    "    major_assets = [(tickers[i], weights[i]) for i in range(len(weights)) if weights[i] > threshold]\n",
    "    minor_assets = [(tickers[i], weights[i]) for i in range(len(weights)) if weights[i] <= threshold]\n",
    "\n",
    "    explanation.append(\"Major Holdings:\")\n",
    "    for name, w in major_assets:\n",
    "        explanation.append(f\"• {name} makes up {w:.2%} of the portfolio — likely due to its lower volatility or better diversification.\")\n",
    "    for name, w in minor_assets:\n",
    "        explanation.append(f\"• {name} makes up {w:.2%} of the portfolio — likely due to its higher volatility or lower diversification benefits.\")\n",
    "\n",
    "    explanation.append(\"\\nExpected Portfolio Performance:\")\n",
    "    explanation.append(f\"The expected annual return is {expected_return:.2%}, with an annualized volatility of {expected_volatility:.2%}.\")\n",
    "\n",
    "    if expected_volatility < 0.2:\n",
    "        explanation.append(\"This indicates a relatively low-risk portfolio, applicable for a conservative approach.\")\n",
    "    elif expected_volatility < 0.35:\n",
    "        explanation.append(\"This indicates a moderate-risk portfolio, suitable for a balanced approach.\")\n",
    "    else:\n",
    "        explanation.append(\"This indicates a high-risk portfolio, suitable for investors with a more aggressive preference.\")\n",
    "\n",
    "    return \"\\n\".join(explanation)\n",
    "\n",
    "explanation = explain_min_var_portfolio(\n",
    "    weights=optimal_weights,\n",
    "    tickers=list(df_returns.columns),\n",
    "    expected_return=expected_return,\n",
    "    expected_volatility=expected_volatility,\n",
    ")\n",
    "\n",
    "print(explanation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "57ecd229",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Portfolio 1 day VaR at 95% confidence level: -1.99%\n",
      "\n",
      "Interpreting the results:\n",
      "There is a 5.0% chance that the portfolio can lose more than -1.99% of its value in one day.\n"
     ]
    }
   ],
   "source": [
    "# CALCULATE PORTFOLIO PARAMETRIC VALUE AT RISK (VaR) USING COVARIANCE MATRIX\n",
    "def portfolio_var(df_returns, weights, alpha=0.05):\n",
    "    \"\"\"\n",
    "    Calculates 1-day parametric Value at Risk (VaR) for the entire portfolio.\n",
    "\n",
    "    Parameters:\n",
    "        df_returns (pd.DataFrame): Daily returns\n",
    "        weights (list or np.ndarray): Portfolio weights (sum to 1)\n",
    "        alpha (float): Significance level (e.g., 0.05 for 95% confidence)\n",
    "\n",
    "    Returns:\n",
    "        float: 1-day VaR as a positive percentage\n",
    "    \"\"\"\n",
    "\n",
    "    weights = np.array(weights)\n",
    "    z_score = norm.ppf(1 - alpha)  # Z-score for the given confidence level\n",
    "\n",
    "    mu_p = np.dot(weights, df_returns.mean())  # Portfolio mean return\n",
    "    sigma_p = np.sqrt(np.dot(weights, np.dot(df_returns.cov(), weights)))  # Portfolio volatility\n",
    "\n",
    "    var_port = -(mu_p + z_score * sigma_p)  # VaR formula\n",
    "\n",
    "    return var_port\n",
    "\n",
    "# TESTING THE FUNCTION\n",
    "var_portfolio_95 = portfolio_var(df_returns, optimal_weights, alpha=0.05)\n",
    "print(f\"Portfolio 1 day VaR at 95% confidence level: {var_portfolio_95:.2%}\")\n",
    "\n",
    "# INTERPRET RESULTS\n",
    "print(\"\\nInterpreting the results:\")\n",
    "print(f\"There is a {alpha*100}% chance that the portfolio can lose more than {var_portfolio_95:.2%} of its value in one day.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3431ec09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Interpreting Portfolio-Level Value at Risk (95% Confidence):\n",
      "Based on your actual portfolio allocation, there is a 5% chance the portfolio could lose more than -1.99% of its value in a single trading day.\n",
      "For a portfolio valued at $100,000, this translates to a potential 1-day loss exceeding $-1,985.89.\n",
      "This estimate assumes normal market conditions and historical return patterns.\n"
     ]
    }
   ],
   "source": [
    "# CONVERT TO DOLLAR VAR\n",
    "def dollar_var(portfolio_value, var_percentage):\n",
    "    \"\"\"\n",
    "    Converts percentage VaR to dollar amount.\n",
    "\n",
    "    Parameters:\n",
    "        portfolio_value (float): Total value of the portfolio (e.g., $100,000)\n",
    "        var_percentage (float): VaR as a decimal (e.g., 0.0243 for 2.43%)\n",
    "\n",
    "    Returns:\n",
    "        float: Dollar value at risk\n",
    "    \"\"\"\n",
    "    return portfolio_value * var_percentage\n",
    "\n",
    "# HYPOTHETICAL PORTFOLIO VALUE\n",
    "portfolio_value = 100000  # Example: $100,000\n",
    "\n",
    "# CALCULATE DOLLAR VAR USING MODEL OUTPUT\n",
    "dollar_var_result = dollar_var(portfolio_value, var_portfolio_95)\n",
    "\n",
    "# INTERPRETATION OUTPUT\n",
    "print(\"\\nInterpreting Portfolio-Level Value at Risk (95% Confidence):\")\n",
    "print(f\"Based on your actual portfolio allocation, there is a 5% chance the portfolio could lose more than {var_portfolio_95:.2%} of its value in a single trading day.\")\n",
    "print(f\"For a portfolio valued at ${portfolio_value:,.0f}, this translates to a potential 1-day loss exceeding ${dollar_var_result:,.2f}.\")\n",
    "print(\"This estimate assumes normal market conditions and historical return patterns.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "06696485",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import psycopg2\n",
    "from sqlalchemy import create_engine\n",
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a5969d7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-16 09:16:56,161 - INFO - Data exported to PostgreSQL database successfully, portfolio risk metrics with timestamps appended successfully.\n",
      "2025-04-16 09:16:56,175 - INFO - Portfolio summary exported to PostgreSQL successfully.\n",
      "2025-04-16 09:16:56,178 - INFO - PostgreSQL connection closed.\n"
     ]
    }
   ],
   "source": [
    "# CREATE ETL PIPLINE TO PGADMIN RELATION DATABASE\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Extract credentials from environment variables\n",
    "user = os.getenv(\"PG_USER\")\n",
    "password = os.getenv(\"PG_PASSWORD\")\n",
    "host = os.getenv(\"PG_HOST\")\n",
    "port = os.getenv(\"PG_PORT\")\n",
    "db = os.getenv(\"PG_DB\")\n",
    "\n",
    "# Check if credentials are loaded\n",
    "if not all([user, password, host, port, db]):\n",
    "    raise ValueError(\"Database credentials are not set in the environment variables.\")\n",
    "\n",
    "\n",
    "# Add time stamp to the DataFrame\n",
    "timestamp = pd.Timestamp.now()\n",
    "\n",
    "\n",
    "# Build DataFrame\n",
    "summary_df = pd.DataFrame({\n",
    "    'ticker': df_returns.columns,\n",
    "    'sharpe_ratio': sharpe_ratios,\n",
    "    'var_95': var_95,\n",
    "    'var_param_95': var_param_95,\n",
    "    'max_drawdown': max_dd,\n",
    "    'rolling_vol_20d': rolling_vol.tail(1).T.values.flatten(),\n",
    "    'optimal_weight': optimal_weights,\n",
    "    'timestamp': timestamp,\n",
    "})\n",
    "\n",
    "\n",
    "# PostgreSQL connection parameters\n",
    "engine = create_engine(f'postgresql+psycopg2://{user}:{password}@{host}:{port}/{db}')\n",
    "\n",
    "\n",
    "# Export to SQL and overwrite existing table\n",
    "try:\n",
    "\n",
    "    summary_df.to_sql(\"risk_metrics\", engine, if_exists='append', index=False)\n",
    "    logger.info(\"Data exported to PostgreSQL database successfully, portfolio risk metrics with timestamps appended successfully.\")\n",
    "\n",
    "    expected_return, expected_volatility = portfolio_performance(df_returns, optimal_weights)\n",
    "    var_portfolio_95 = portfolio_var(df_returns, optimal_weights, alpha=0.05)\n",
    "\n",
    "    portfolio_summary_df = pd.DataFrame([{\n",
    "        'timestamp': timestamp,\n",
    "        'portfolio_return': expected_return,\n",
    "        'portfolio_volatility': expected_volatility,\n",
    "        'portfolio_var': var_portfolio_95\n",
    "    }])\n",
    "\n",
    "    portfolio_summary_df.to_sql(\"portfolio_summary\", engine, if_exists='append', index=False)\n",
    "    logger.info(\"Portfolio summary exported to PostgreSQL successfully.\")\n",
    "\n",
    "except Exception as e:\n",
    "    logger.error(f\"Error exporting data to PostgreSQL: {e}\")\n",
    "finally:\n",
    "    engine.dispose()\n",
    "    logger.info(\"PostgreSQL connection closed.\")\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
