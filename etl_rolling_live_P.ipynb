{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e67ec1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import logging\n",
    "from dotenv import load_dotenv\n",
    "from sqlalchemy import create_engine\n",
    "import yfinance as yf\n",
    "import datetime as datetime\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66e6078b",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "load_dotenv()\n",
    "# Load environment variables\n",
    "\n",
    "user = os.getenv('PG_USER')\n",
    "password = os.getenv('PG_PASSWORD')\n",
    "host = os.getenv('PG_HOST')\n",
    "port = os.getenv('PG_PORT')\n",
    "database = os.getenv('PG_DB')\n",
    "\n",
    "if not all([user, password, host, port, database]):\n",
    "    raise ValueError(\"One or more environment variables are not set. Please check your .env file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5bd684bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FETCH 30 DAY LIVE DATA FROM YAHOO FINANCE\n",
    "def fetch_recent_data(tickers, period=\"30d\", interval=\"1d\"):\n",
    "    \"\"\"\n",
    "    Fetch recent historical price data from yfinance.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        logger.info(f\"Fetching {period} of data for tickers: {', '.join(tickers)}\")\n",
    "        data = yf.download(tickers, period=period, interval=interval, group_by='ticker', auto_adjust=True)\n",
    "\n",
    "        if data.empty:\n",
    "            logger.warning(\"No data returned from yfinance.\")\n",
    "            return pd.DataFrame()\n",
    "\n",
    "        if isinstance(data.columns, pd.MultiIndex):\n",
    "            try:\n",
    "                return data['Close']\n",
    "            except KeyError:\n",
    "                close_data = pd.DataFrame({\n",
    "                    ticker: data[ticker]['Close']\n",
    "                    for ticker in data.columns.levels[0]\n",
    "                    if 'Close' in data[ticker]\n",
    "                })\n",
    "                return close_data\n",
    "        else:\n",
    "            return data\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error fetching stock data: {e}\")\n",
    "        return pd.DataFrame()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "282c7bf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-16 09:16:09,745 - INFO - Fetching 30d of data for tickers: AAPL, MSFT, TSLA, JNJ, NVDA\n",
      "[*********************100%***********************]  5 of 5 completed\n",
      "C:\\Users\\roman\\AppData\\Local\\Temp\\ipykernel_10068\\3666117503.py:19: FutureWarning: The default fill_method='pad' in DataFrame.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  returns = price_df.pct_change().dropna()\n",
      "2025-04-16 09:16:10,142 - INFO - Simulated data for 2025-04-16 exported.\n",
      "2025-04-16 09:16:10,152 - INFO - Simulated data for 2025-04-15 exported.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample of calculated rolling risk metrics:\n",
      "  ticker  sharpe_ratio  var_param_95                  timestamp\n",
      "0   AAPL     -0.103734     -0.066550 2025-04-16 09:16:09.951992\n",
      "1    JNJ     -0.117804     -0.030162 2025-04-16 09:16:09.951992\n",
      "2   MSFT     -0.060975     -0.039767 2025-04-16 09:16:09.951992\n",
      "3   NVDA      0.030890     -0.083927 2025-04-16 09:16:09.951992\n",
      "4   TSLA      0.014199     -0.118032 2025-04-16 09:16:09.951992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-16 09:16:10,164 - INFO - Simulated data for 2025-04-14 exported.\n",
      "2025-04-16 09:16:10,177 - INFO - Simulated data for 2025-04-13 exported.\n",
      "2025-04-16 09:16:10,194 - INFO - Simulated data for 2025-04-12 exported.\n",
      "2025-04-16 09:16:10,208 - INFO - Simulated data for 2025-04-11 exported.\n",
      "2025-04-16 09:16:10,228 - INFO - Simulated data for 2025-04-10 exported.\n",
      "2025-04-16 09:16:10,230 - INFO - PostgreSQL connection closed after simulation.\n"
     ]
    }
   ],
   "source": [
    "# CALCULATE SHARPE RATIO AND PARAMETRIC VAR\n",
    "\n",
    "def calculate_rolling_risk_metrics(price_df, alpha=0.05, risk_free_rate=0.03):\n",
    "    \"\"\"\n",
    "    Calculate Sharpe Ratio and Parametric VaR for each asset using 30-day data.\n",
    "\n",
    "    Parameters:\n",
    "        price_df (pd.DataFrame): Price data (Date index, tickers as columns)\n",
    "        alpha (float): Confidence level (e.g., 0.05 for 95%)\n",
    "        risk_free_rate (float): Annual risk-free rate\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: One-row DataFrame of metrics per ticker with timestamp.\n",
    "    \"\"\"\n",
    "    if price_df.empty:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # Calculate daily returns\n",
    "    returns = price_df.pct_change().dropna()\n",
    "\n",
    "    # Risk-free daily rate\n",
    "    rf_daily = (1 + risk_free_rate) ** (1/252) - 1\n",
    "\n",
    "    # Metrics\n",
    "    mu = returns.mean()\n",
    "    sigma = returns.std()\n",
    "    sharpe_ratios = (mu - rf_daily) / sigma\n",
    "\n",
    "    z = norm.ppf(1 - alpha)\n",
    "    var_param = -(mu + z * sigma)\n",
    "\n",
    "    # Timestamp for export\n",
    "    timestamp = pd.Timestamp.now()\n",
    "\n",
    "    # Assemble result\n",
    "    result_df = pd.DataFrame({\n",
    "        'ticker': mu.index,\n",
    "        'sharpe_ratio': sharpe_ratios.values,\n",
    "        'var_param_95': var_param.values,\n",
    "        'timestamp': timestamp\n",
    "    })\n",
    "\n",
    "    return result_df\n",
    "\n",
    "# Test Functions\n",
    "\n",
    "# Example tickers\n",
    "tickers = ['AAPL', 'MSFT', 'TSLA', 'JNJ', 'NVDA']\n",
    "\n",
    "# Fetch recent data\n",
    "price_data = fetch_recent_data(tickers)\n",
    "\n",
    "# Calculate metrics\n",
    "rolling_metrics_df = calculate_rolling_risk_metrics(price_data)\n",
    "\n",
    "# Preview the result\n",
    "if rolling_metrics_df.empty:\n",
    "    logger.warning(\"No metrics calculated. Exiting.\")\n",
    "    exit()\n",
    "else:\n",
    "    print(\"\\nSample of calculated rolling risk metrics:\")\n",
    "    print(rolling_metrics_df)\n",
    "\n",
    "# Simulate past 7 days for testing purposes\n",
    "from datetime import timedelta\n",
    "\n",
    "engine = create_engine(f'postgresql+psycopg2://{user}:{password}@{host}:{port}/{database}')\n",
    "\n",
    "try:\n",
    "    for i in range(7):\n",
    "        simulated_df = rolling_metrics_df.copy()\n",
    "        simulated_df['timestamp'] = pd.Timestamp.now() - timedelta(days=i)\n",
    "\n",
    "        simulated_df.to_sql(\"rolling_risk_metrics\", engine, if_exists='append', index=False)\n",
    "        logger.info(f\"Simulated data for {simulated_df['timestamp'].iloc[0].date()} exported.\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Error during simulation export: {e}\")\n",
    "finally:\n",
    "    engine.dispose()\n",
    "    logger.info(\"PostgreSQL connection closed after simulation.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3adc2cd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-16 09:16:13,369 - INFO - Rolling risk metrics successfully exported to PostgreSQL.\n",
      "2025-04-16 09:16:13,372 - INFO - PostgreSQL connection closed.\n"
     ]
    }
   ],
   "source": [
    "# EXPORT TO POSTGRESQL DATABASE\n",
    "\n",
    "engine = create_engine(f'postgresql+psycopg2://{user}:{password}@{host}:{port}/{database}')\n",
    "\n",
    "try:\n",
    "    rolling_metrics_df.to_sql(\"rolling_risk_metrics\", engine, if_exists='append', index=False)\n",
    "    logger.info(\"Rolling risk metrics successfully exported to PostgreSQL.\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Error exporting rolling risk metrics: {e}\")\n",
    "finally:\n",
    "    engine.dispose()\n",
    "    logger.info(\"PostgreSQL connection closed.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
